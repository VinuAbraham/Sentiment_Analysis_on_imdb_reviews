{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    \n",
    "    clean_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    \n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>first think another Disney movie, might good, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Put aside Dr. House repeat missed, Desperate H...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>big fan Stephen King's work, film made even gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watched horrid thing TV. Needless say one movi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>truly enjoyed film. acting terrific plot. Jeff...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       SentimentText  Sentiment\n",
       "0  first think another Disney movie, might good, ...          1\n",
       "1  Put aside Dr. House repeat missed, Desperate H...          0\n",
       "2  big fan Stephen King's work, film made even gr...          1\n",
       "3  watched horrid thing TV. Needless say one movi...          0\n",
       "4  truly enjoyed film. acting terrific plot. Jeff...          1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [first, think, another, Disney, movie, might, ...\n",
       "1        [Put, aside, Dr, House, repeat, missed, Desper...\n",
       "2        [big, fan, Stephen, Kings, work, film, made, e...\n",
       "3        [watched, horrid, thing, TV, Needless, say, on...\n",
       "4        [truly, enjoyed, film, acting, terrific, plot,...\n",
       "5        [memory, Last, Hunt, stuck, since, saw, 1956, ...\n",
       "6        [Shakespeare, fan, appreciate, Ken, Branagh, d...\n",
       "7        [privilege, watching, Scarface, big, screen, b...\n",
       "8        [real, classic, shipload, sailors, trying, get...\n",
       "9        [Serials, short, subjects, originally, shown, ...\n",
       "10       [strange, sex, comedy, theres, little, comedy,...\n",
       "11       [many, problems, film, worst, continuity, reed...\n",
       "12       [Rosie, wasted, lot, TV, time, talking, Tainos...\n",
       "13       [Man, people, got, chill, movie, artistic, gen...\n",
       "14       [great, movie, could, Soylent, Green, scenes, ...\n",
       "15       [Wonderful, family, dramacomedy, starring, Mac...\n",
       "16       [Ko, tamo, peva, one, best, films, ever, saw, ...\n",
       "17       [quite, long, time, life, either, like, film, ...\n",
       "18       [Kolchak, TV, series, really, didnt, fit, cate...\n",
       "19       [rare, find, literary, work, adequately, trans...\n",
       "20       [awful, awful, old, room, mate, used, watch, j...\n",
       "21       [mom, recently, become, addicted, show, laughi...\n",
       "22       [okay, plain, dumb, bad, horrorcomedy, film, r...\n",
       "23       [film, mesmerizing, beauty, creativity, artist...\n",
       "24       [Filmfour, going, lot, better, little, snot, f...\n",
       "25       [60s, 1999, Mark, Piznarski, Josh, Hamilton, J...\n",
       "26       [show, suck, Unfortunately, really, question, ...\n",
       "27       [Sometimes, want, laugh, Dont, analyzing, crit...\n",
       "28       [antibush, jokes, get, really, easy, show, lik...\n",
       "29       [others, noted, excellent, Hammerstyle, film, ...\n",
       "                               ...                        \n",
       "24970    [almost, ideal, romantic, anime, MUST, SEE, AG...\n",
       "24971    [Unfortunately, film, long, unavailable, poste...\n",
       "24972    [12, Diane, Keaton, farcebr, br, Someone, tell...\n",
       "24973    [Film, looking, glass, see, world, new, light,...\n",
       "24974    [empty, lack, lustre, rendition, classic, nove...\n",
       "24975    [movie, good, example, extreme, lack, good, wr...\n",
       "24976    [movie, really, great, flick, something, affec...\n",
       "24977    [Darkling, interesting, entertaining, film, F,...\n",
       "24978    [Marlon, Brando, Frank, Sinatra, HATED, film, ...\n",
       "24979    [2004, liked, became, stupid, suggests, kids, ...\n",
       "24980    [avoid, making, type, film, future, film, inte...\n",
       "24981    [Wow, 5, hours, Riget, Lars, continues, great,...\n",
       "24982    [Marvelous, James, Stewart, Vera, Miles, vehic...\n",
       "24983    [characters, depthless, rip, offs, youve, seen...\n",
       "24984    [countless, talkinganimal, films, past, majori...\n",
       "24985    [absurdist, dark, comedy, Belgium, Shot, perfe...\n",
       "24986    [nice, see, Suraj, Barjatya, back, best, atA, ...\n",
       "24987    [movie, poorly, written, poorly, acted, predic...\n",
       "24988    [unpretentious, Horror, film, probably, destin...\n",
       "24989    [saw, Saving, Grace, right, came, video, Since...\n",
       "24990    [Taking, old, collection, stories, poses, chal...\n",
       "24991    [movie, made, want, become, director, Michelle...\n",
       "24992    [video, thing, think, fourth, attempt, managed...\n",
       "24993    [almost, typical, Lynch, However, makes, film,...\n",
       "24994    [really, must, caught, different, film, rest, ...\n",
       "24995    [kid, 50s, 60s, anything, connected, Disney, d...\n",
       "24996    [course, reading, review, seen, film, already,...\n",
       "24997    [read, Theres, Girl, Soup, came, Peter, Seller...\n",
       "24998    [film, quite, boring, snippets, naked, flesh, ...\n",
       "24999    [Although, film, somewhat, filled, eighties, c...\n",
       "Name: SentimentText, Length: 25000, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['SentimentText'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data['SentimentText'],data['Sentiment'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=process_text)), # converts strings to integer counts\n",
    "    ('tfidf',TfidfTransformer()), # converts integer counts to weighted TF-IDF scores\n",
    "    ('classifier',MultinomialNB()) # train on TF-IDF vectors with Naive Bayes classifier\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('bow',\n",
       "                 CountVectorizer(analyzer=<function process_text at 0x7f2d6f993268>,\n",
       "                                 binary=False, decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('classifier',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.869\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
